{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccq-E5XSlVb8"
      },
      "source": [
        "### This notebook contains all the code needed to develop a customized environment and train/validation.\n",
        "Once finish, should put them separately into project folder. Putting them in this single notebook is just for convenience to run in Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN1UaGpLz3UI"
      },
      "source": [
        "### change sys.path.append() based on your mounting path. The .ipynb is located within newgymrepo-Main/gym-sokoban/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtAvi-4FBgMs",
        "outputId": "0e1907a9-9e5e-44f2-a4be-ad8161f1d035"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('/content/drive/MyDrive/gym-sokoban/')\n",
        "base_dir = \"/content/drive/MyDrive/gym-sokoban\"\n",
        "log_file_name = \"/content/sokoban_env.txt\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# sys.path.append(\"/Users/evansun/Documents/Claudia/CS5446 AI_planning_decision_making/project/my-gym-repo/otherRepo/gym-sokoban-default\")\n",
        "# base_dir = \"/Users/evansun/Documents/Claudia/CS5446 AI_planning_decision_making/project/my-gym-repo/otherRepo/gym-sokoban-default\"\n",
        "# log_file_name = base_path + \"/\" + \"sokoban_log.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQ37eKLPtuM9",
        "outputId": "9ad7e55f-84ea-44e5-c64c-e411c2cac336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.6.0\n",
            "Collecting Shimmy\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from Shimmy) (2.0.2)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /usr/local/lib/python3.11/dist-packages (from Shimmy) (1.1.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->Shimmy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->Shimmy) (4.13.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->Shimmy) (0.0.4)\n",
            "Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: Shimmy\n",
            "Successfully installed Shimmy-2.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gym\n",
        "!pip install stable_baselines3\n",
        "!pip install Shimmy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBMuye6ez3UI"
      },
      "source": [
        "## generate maps (only run when necessary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aZSWAi6sz3UI"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "\n",
        "\n",
        "# Constants for tile types\n",
        "FLOOR   = 0\n",
        "WALL    = 1\n",
        "BOX     = 2\n",
        "TARGET  = 3\n",
        "BOX_ON_TARGET = 4  # not used in generation directly\n",
        "PLAYER  = 5\n",
        "\n",
        "BOARD_WIDTH = 10\n",
        "BOARD_HEIGHT = 10\n",
        "\n",
        "def generate_base_map(width=10, height=10, difficulty=1):\n",
        "    \"\"\"\n",
        "    Create a grid with walls on the borders and floor in the interior.\n",
        "    \"\"\"\n",
        "    if difficulty < 4:\n",
        "        board = np.zeros((height, width), dtype=int)\n",
        "        board[0:3, :] = WALL\n",
        "        board[height-3:height, :] = WALL\n",
        "        board[:, 0:3] = WALL\n",
        "        board[:, width-3:width] = WALL\n",
        "    elif difficulty < 7:\n",
        "        board = np.zeros((height, width), dtype=int)\n",
        "        board[0:2, :] = WALL\n",
        "        board[height-2:height, :] = WALL\n",
        "        board[:, 0:2] = WALL\n",
        "        board[:, width-2:width] = WALL\n",
        "    else:\n",
        "        board = np.zeros((height, width), dtype=int)\n",
        "        board[0, :] = WALL\n",
        "        board[-1, :] = WALL\n",
        "        board[:, 0] = WALL\n",
        "        board[:, -1] = WALL\n",
        "    return board\n",
        "\n",
        "def add_random_walls(board, wall_density):\n",
        "    \"\"\"\n",
        "    Fill internal cells (not borders) with walls randomly according to the density.\n",
        "\n",
        "    Parameters:\n",
        "      board: the base map\n",
        "      wall_density: a float (0 to 1) representing the probability of placing a wall\n",
        "    \"\"\"\n",
        "    height, width = board.shape\n",
        "    for i in range(1, height-1):\n",
        "        for j in range(1, width-1):\n",
        "            # Only add a wall if the cell is not already a wall.\n",
        "            if board[i, j] == FLOOR and np.random.random() < wall_density:\n",
        "                board[i, j] = WALL\n",
        "    return board\n",
        "\n",
        "def place_elements(board, n_boxes, n_targets):\n",
        "    \"\"\"\n",
        "    Randomly place a single player, boxes, and targets in available floor spaces.\n",
        "\n",
        "    The function assumes that there is enough space.\n",
        "    \"\"\"\n",
        "    free_positions = list(zip(*np.where(board == FLOOR)))\n",
        "    if len(free_positions) < (n_boxes + n_targets + 1):\n",
        "        raise ValueError(\"Not enough free cells to place all elements.\")\n",
        "\n",
        "    # Shuffle the list so placements are random.\n",
        "    np.random.shuffle(free_positions)\n",
        "\n",
        "    # Place the player first:\n",
        "    player_pos = free_positions.pop()\n",
        "    board[player_pos] = PLAYER\n",
        "\n",
        "    # Place boxes:\n",
        "    boxes = []\n",
        "    for _ in range(n_boxes):\n",
        "        pos = free_positions.pop()\n",
        "        board[pos] = BOX\n",
        "        boxes.append(pos)\n",
        "\n",
        "    # Place targets:\n",
        "    targets = []\n",
        "    for _ in range(n_targets):\n",
        "        pos = free_positions.pop()\n",
        "        board[pos] = TARGET\n",
        "        targets.append(pos)\n",
        "\n",
        "    return board, player_pos, boxes, targets\n",
        "\n",
        "def choose_map(map_path, difficulty):\n",
        "    \"\"\"\n",
        "    Load Sokoban puzzles with human solutions from text files.\n",
        "\n",
        "    Args:\n",
        "        directory_path: Path to directory containing puzzle files\n",
        "\n",
        "    Returns:\n",
        "        list of tuples: (puzzle_state, solution_moves)\n",
        "    \"\"\"\n",
        "    puzzle = []\n",
        "\n",
        "    file_list = []\n",
        "    for filename in os.listdir(map_path):\n",
        "        # choose the .txt file with the specified difficulty level\n",
        "        if not filename.endswith('.txt') or not filename.startswith(str(difficulty) + \"_\"):\n",
        "            continue\n",
        "\n",
        "        file_list.append(filename)\n",
        "\n",
        "    chosen_filename = random.choice(file_list)\n",
        "\n",
        "    filepath = os.path.join(map_path, chosen_filename)\n",
        "    print(filepath)\n",
        "    with open(filepath, 'r') as f:\n",
        "        for line in f:\n",
        "            content = line.strip()\n",
        "            if \"#\" in content:\n",
        "                puzzle.append(content)\n",
        "            elif content.strip() != \"\":\n",
        "                solution = content\n",
        "\n",
        "    return puzzle, solution, chosen_filename\n",
        "\n",
        "\n",
        "def generate_map(width, height, difficulty):\n",
        "    \"\"\"\n",
        "    Generate one Sokoban map based on the specified difficulty.\n",
        "\n",
        "    The difficulty parameter is used to tweak:\n",
        "      - number of boxes (and targets)\n",
        "      - wall density (more walls → more obstacles)\n",
        "\n",
        "    You can adjust the parameters as needed.\n",
        "    \"\"\"\n",
        "    if difficulty == 1:\n",
        "        n_boxes = 1\n",
        "        wall_density = 0.0  # No extra obstacles\n",
        "        n_targets = 1\n",
        "    elif difficulty == 2:\n",
        "        n_boxes = 1\n",
        "        wall_density = 0.05  # Sparse obstacles\n",
        "        n_targets = 1\n",
        "    elif difficulty == 3:\n",
        "        n_boxes = 1\n",
        "        wall_density = 0.05  # A few obstacles to force slight navigation issues\n",
        "        n_targets = 1\n",
        "    elif difficulty == 4:\n",
        "        n_boxes = 2\n",
        "        wall_density = 0.0  # More obstacles in the field\n",
        "        n_targets = 2\n",
        "    elif difficulty == 5:\n",
        "        n_boxes = 2\n",
        "        wall_density = 0.05  # Dense obstacles, which can lead to tricky deadlock situations\n",
        "        n_targets = 2\n",
        "    elif difficulty == 6:\n",
        "        n_boxes = 3\n",
        "        wall_density = 0.0  # Dense obstacles, which can lead to tricky deadlock situations\n",
        "        n_targets = 3\n",
        "    elif difficulty == 7:\n",
        "        n_boxes = 2\n",
        "        wall_density = 0.05  # Dense obstacles, which can lead to tricky deadlock situations\n",
        "        n_targets = 2\n",
        "    elif difficulty == 8:\n",
        "        n_boxes = 2\n",
        "        wall_density = 0.05  # Dense obstacles, which can lead to tricky deadlock situations\n",
        "        n_targets = 3\n",
        "    else:\n",
        "        raise ValueError(\"Unknown difficulty level.\")\n",
        "\n",
        "    # Create the base board (you can also vary width/height if desired)\n",
        "    board = generate_base_map(width, height, difficulty)\n",
        "    board = add_random_walls(board, wall_density)\n",
        "    board, player, boxes, targets = place_elements(board, n_boxes, n_targets)\n",
        "    return board\n",
        "\n",
        "def convert_to_deepmind_format(board):\n",
        "    map = \"\"\n",
        "    # print(board)\n",
        "    for i in range(BOARD_HEIGHT):\n",
        "        line = \"\"\n",
        "        for j in range(BOARD_WIDTH):\n",
        "            if board[i][j] == WALL:\n",
        "                line += \"#\"\n",
        "            elif board[i][j] == FLOOR:\n",
        "                line += \" \"\n",
        "            elif board[i][j] == PLAYER:\n",
        "                line += \"@\"\n",
        "            elif board[i][j] == BOX:\n",
        "                line += \"$\"\n",
        "            elif board[i][j] == TARGET:\n",
        "                line += \".\"\n",
        "        line += \"\\n\"\n",
        "        map += line\n",
        "    return map\n",
        "\n",
        "\n",
        "def delete_files_in_directory(directory_path):\n",
        "   try:\n",
        "     shutil.rmtree(directory_path)\n",
        "     print(\"All files deleted successfully.\")\n",
        "   except OSError:\n",
        "     print(\"Error occurred while deleting files.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3fqqCrnanpLF"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "from PIL import Image, ImageFont, ImageDraw\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import imageio\n",
        "\n",
        "## from Sarjune's code\n",
        "\n",
        "def create_gif(observations, filename=\"sokoban.gif\", success=False, is_maxsteps = False):\n",
        "    \"\"\"Create GIF from observations\"\"\"\n",
        "    if not observations:\n",
        "        print(\"No observations to visualize\")\n",
        "        return\n",
        "\n",
        "    images = []\n",
        "    total_frames = len(observations)\n",
        "    for i in range(total_frames):\n",
        "\n",
        "        # Get observation and ensure correct format\n",
        "        obs = observations[i]\n",
        "        if len(obs.shape) == 3 and obs.shape[0] == 3:  # (C, H, W) format\n",
        "            obs = np.transpose(obs, (1, 2, 0))  # Convert to (H, W, C)\n",
        "\n",
        "        # Create PIL image\n",
        "        img = Image.fromarray(obs.astype('uint8'))\n",
        "\n",
        "        if i == total_frames-1:\n",
        "            Im = ImageDraw.Draw(img)\n",
        "            if success:\n",
        "                Im.text((20, 20), \"Success!\",fill=(255, 255, 255))\n",
        "            else:\n",
        "                if is_maxsteps:\n",
        "                    Im.text((50, 30), \"Fail! max_steps!\",fill=(255, 255, 255))\n",
        "                else:\n",
        "                    Im.text((50, 30), \"Fail! push to corner\",fill=(255, 255, 255))\n",
        "        images.append(img)\n",
        "\n",
        "\n",
        "    # Save as GIF\n",
        "    if images:\n",
        "        images[0].save(\n",
        "            filename,\n",
        "            save_all=True,\n",
        "            append_images=images[1:],\n",
        "            # duration=100//fps,\n",
        "            loop=1\n",
        "        )\n",
        "        print(f\"GIF saved to {filename}\")\n",
        "\n",
        "    else:\n",
        "        print(\"No images to create GIF\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SG4OE3BfloVn"
      },
      "source": [
        "## Customize_boxoban_env.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkMoHAD1lTfd"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "from gym.utils import seeding\n",
        "from gym.spaces.discrete import Discrete\n",
        "from gym.spaces import Box\n",
        "\n",
        "import gym_sokoban.envs.room_utils as room_utils\n",
        "# from .render_utils import room_to_rgb, room_to_tiny_world_rgb\n",
        "# import numpy as np\n",
        "import gym_sokoban.envs.sokoban_env as sokoban_env\n",
        "from gym_sokoban.envs.render_utils import room_to_rgb, room_to_tiny_world_rgb\n",
        "\n",
        "# from .boxoban_env import BoxobanEnv\n",
        "# from .render_utils import room_to_rgb\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import requests\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "PUSH_ACTION_LOOKUP = {\n",
        "    0: 'no operation',\n",
        "    1: 'push up',\n",
        "    2: 'push down',\n",
        "    3: 'push left',\n",
        "    4: 'push right',\n",
        "    5: 'move up',\n",
        "    6: 'move down',\n",
        "    7: 'move left',\n",
        "    8: 'move right',\n",
        "}\n",
        "\n",
        "# Moves are mapped to coordinate changes as follows\n",
        "# 0: Move up\n",
        "# 1: Move down\n",
        "# 2: Move left\n",
        "# 3: Move right\n",
        "CHANGE_COORDINATES = {\n",
        "    0: (-1, 0),\n",
        "    1: (1, 0),\n",
        "    2: (0, -1),\n",
        "    3: (0, 1)\n",
        "}\n",
        "\n",
        "RENDERING_MODES = ['rgb_array', 'human', 'tiny_rgb_array', 'tiny_human', 'raw']\n",
        "\n",
        "\n",
        "def manhattan_distance(p1, p2):\n",
        "    return abs(p1[0] - p2[0]) + abs(p1[1] - p2[1])\n",
        "\n",
        "class CustomizeSokobanEnv(gym.Env):\n",
        "    metadata = {\n",
        "        'render.modes': ['human', 'rgb_array', 'tiny_human', 'tiny_rgb_array', 'raw'],\n",
        "        'render_modes': ['human', 'rgb_array', 'tiny_human', 'tiny_rgb_array', 'raw']\n",
        "    }\n",
        "\n",
        "    def __init__(self,\n",
        "                 selected_map = None,\n",
        "                 subgoal_map_array = None,\n",
        "                 dim_room=(10, 10),\n",
        "                 max_steps=100,\n",
        "                 num_boxes=3,\n",
        "                 num_gen_steps=None,\n",
        "                 reset=True,\n",
        "                 difficulty =\"medium\",\n",
        "                 split=\"train\",\n",
        "                 verbose = False\n",
        "                 ):\n",
        "        super().__init__()\n",
        "        self.subgoal_map_array = subgoal_map_array\n",
        "        self.selected_map = selected_map\n",
        "\n",
        "        # General Configuration\n",
        "        self.dim_room = dim_room\n",
        "        if num_gen_steps == None:\n",
        "            self.num_gen_steps = int(1.7 * (dim_room[0] + dim_room[1]))\n",
        "        else:\n",
        "            self.num_gen_steps = num_gen_steps\n",
        "\n",
        "        self.num_boxes = num_boxes\n",
        "        self.difficulty = difficulty\n",
        "        self.split = split\n",
        "        self.verbose = verbose\n",
        "\n",
        "        # represent the total reward for the episode!!\n",
        "        self.reward_last = 0\n",
        "\n",
        "        # Other Settings\n",
        "        self.viewer = None\n",
        "        self.max_steps = max_steps\n",
        "        self.action_space = Discrete(len(PUSH_ACTION_LOOKUP))\n",
        "        # screen_height, screen_width = (dim_room[0] * 16, dim_room[1] * 16)\n",
        "\n",
        "        # Define reward values - adjusted for better learning\n",
        "        self.reward_box_on_target = 2.0     # Increase (was 5.0)\n",
        "        self.reward_box_closer = 0.2         # Increase (was 0.5)\n",
        "        self.reward_puzzle_solved = 10.0     # Larger reward for solving\n",
        "        self.reward_exploration_bonus = 0.25       # Small bonus for trying new states\n",
        "        self.reward_player_explore = 0.2\n",
        "        self.reward_box_closer = 0.2\n",
        "\n",
        "        self.penalty_box_deadend = -10    # Penalty for corner situations\n",
        "        self.penalty_for_step = -0.05          # Reduce (was -0.001)\n",
        "        self.penalty_repeat_walk_around = -0.2\n",
        "\n",
        "\n",
        "        # extra state tracking to use in reward calculation\n",
        "        self.last_step_push_box = 0\n",
        "        self.boxes_on_target = 0\n",
        "        self.box_distances = -1\n",
        "        self.visited_states = []  # Track visited states\n",
        "        self.player_visited_pos = []\n",
        "        self.player_recent_pos =[]\n",
        "        self.walls_pos = []\n",
        "        self.fail = False\n",
        "        self.player_position = None\n",
        "        self.invalid_action = False\n",
        "\n",
        "\n",
        "        # Define symbolic observation space: player (x,y) + each box (x,y)\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0,\n",
        "            high=self.dim_room[0],\n",
        "            shape=(2 + 4 * self.num_boxes + self.dim_room[0] * self.dim_room[1],),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        if reset:\n",
        "            # Initialize Room\n",
        "            _ = self.reset()\n",
        "\n",
        "\n",
        "    def reset(self, render_mode=\"raw\"):\n",
        "        self.num_env_steps = 0\n",
        "        self.reward_last = 0\n",
        "        self.boxes_on_target = 0\n",
        "        self.box_distances = -1\n",
        "        self.visited_states = []\n",
        "        self.player_recent_pos = []\n",
        "        # self.selected_map = selected_map\n",
        "        # self.subgoal_map_array = subgoal_map_array\n",
        "\n",
        "        if self.selected_map is None or self.subgoal_map_array is None:\n",
        "            print(\"please specify selected_map and subgoal_map_array.\")\n",
        "            return\n",
        "\n",
        "        # the generated subgoal is using the digital format, in order to be compatible with self.import_generate_room() settings, convert it to deepmind format first\n",
        "        converted_selected_map = convert_to_deepmind_format(self.selected_map)\n",
        "        self.room_fixed, self.room_state, self.box_mapping = self.import_generate_room(self.selected_map)\n",
        "        self.player_position = np.argwhere(self.room_state == 5)[0]\n",
        "\n",
        "        starting_observation = self.render(mode = render_mode)\n",
        "        return starting_observation\n",
        "\n",
        "\n",
        "    def import_generate_room(self, select_map):\n",
        "        room_fixed = []\n",
        "        room_state = []\n",
        "\n",
        "        '''\n",
        "        Generates a Sokoban room, represented by an integer matrix. The elements are encoded as follows:\n",
        "        wall = 0\n",
        "        empty space = 1\n",
        "        box target = 2\n",
        "        box not on target = 4\n",
        "\n",
        "        player = 5\n",
        "        '''\n",
        "        self.targets = []\n",
        "        self.boxes = []\n",
        "        self.walls_pos = []\n",
        "        for row in select_map:\n",
        "            room_f = []\n",
        "            room_s = []\n",
        "\n",
        "            for e in row:\n",
        "                if e == '#':\n",
        "                    self.walls_pos.append((len(room_fixed), len(room_f)))\n",
        "                    room_f.append(0)\n",
        "                    room_s.append(0)\n",
        "\n",
        "                elif e == '@':\n",
        "                    # C: @ represent player position\n",
        "                    # C: len(room_fixed) represents the row index (starting from 1), len(room_f) represents the column index (starting from 1)\n",
        "                    self.player_position = (len(room_fixed), len(room_f))\n",
        "                    room_f.append(1)\n",
        "                    room_s.append(5)\n",
        "\n",
        "                # represent box\n",
        "                elif e == '$':\n",
        "                    self.boxes.append((len(room_fixed), len(room_f)))\n",
        "                    room_f.append(1)\n",
        "                    room_s.append(4)\n",
        "\n",
        "                # C: represent box target\n",
        "                elif e == '.':\n",
        "                    self.targets.append((len(room_fixed), len(room_f)))\n",
        "                    room_f.append(2)\n",
        "                    room_s.append(2)\n",
        "                elif e == '*':\n",
        "                    # targets\n",
        "                    self.targets.append((len(room_fixed), len(room_f)))\n",
        "                    room_f.append(2)\n",
        "                    room_s.append(2)\n",
        "\n",
        "                    # box\n",
        "                    self.boxes.append((len(room_fixed), len(room_f)))\n",
        "                    room_f.append(1)\n",
        "                    room_s.append(4)\n",
        "\n",
        "                else:\n",
        "                    room_f.append(1)\n",
        "                    room_s.append(1)\n",
        "\n",
        "            # room_f represents all those room elements, wall, player, box, box targets. They are represented by different number\n",
        "            room_fixed.append(room_f)\n",
        "            room_state.append(room_s)\n",
        "\n",
        "        # the initial boxes and player position. Store them to be used in reward calculation\n",
        "        self.visited_states.append((self.boxes + [(self.player_position[0], self.player_position[1])]))\n",
        "        # used for replay in room generation, unused here because pre-generated levels\n",
        "        box_mapping = {}\n",
        "\n",
        "        return np.array(room_fixed), np.array(room_state), box_mapping\n",
        "\n",
        "    # not used actually ...\n",
        "    def seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "\n",
        "    def _push(self, action):\n",
        "        \"\"\"\n",
        "        Perform a push, if a box is adjacent in the right direction.\n",
        "        If no box, can be pushed, try to move.\n",
        "        :param action:\n",
        "        :return: Boolean, indicating a change of the room's state\n",
        "        \"\"\"\n",
        "        change = CHANGE_COORDINATES[(action - 1) % 4]\n",
        "        new_player_position = (self.player_position[0] + change[0], self.player_position[1] + change[1])\n",
        "        current_player_position = self.player_position\n",
        "\n",
        "        # No push, if the push would get the box out of the room's grid\n",
        "        new_box_position = (new_player_position[0] + change[0], new_player_position[1] + change[1])\n",
        "        if new_box_position[0] >= self.room_state.shape[0] \\\n",
        "                or new_box_position[1] >= self.room_state.shape[1]:\n",
        "            return False, False\n",
        "\n",
        "\n",
        "        can_push_box = self.room_state[new_player_position[0], new_player_position[1]] in [3, 4]\n",
        "        can_push_box &= self.room_state[new_box_position[0], new_box_position[1]] in [1, 2]\n",
        "        if can_push_box:\n",
        "\n",
        "            # self.room_state records each position's type: wall = 0, empty space = 1, box target = 2, box not on target = 4, player = 5\n",
        "            # Move Player\n",
        "            self.player_position = new_player_position\n",
        "            self.room_state[(new_player_position[0], new_player_position[1])] = 5\n",
        "            self.room_state[current_player_position[0], current_player_position[1]] = \\\n",
        "                self.room_fixed[current_player_position[0], current_player_position[1]]\n",
        "\n",
        "            # Move Box\n",
        "            box_type = 4\n",
        "            if self.room_fixed[new_box_position[0], new_box_position[1]] == 2:\n",
        "                box_type = 3\n",
        "            self.room_state[new_box_position[0], new_box_position[1]] = box_type\n",
        "\n",
        "            # update boxes position and sort - prepare for reward calculation\n",
        "            self.boxes = [box for box in self.boxes if not (box[0] == self.player_position[0] and box[1] == self.player_position[1])]\n",
        "            self.boxes.append(new_box_position)\n",
        "            self.boxes.sort()\n",
        "            self.last_step_push_box = self.num_env_steps\n",
        "\n",
        "            if len(self.player_recent_pos) > 5:\n",
        "                self.player_recent_pos.pop(0)\n",
        "            self.player_recent_pos.append(self.player_position)\n",
        "            return True, True\n",
        "\n",
        "        # Try to move if no box to push, available\n",
        "        else:\n",
        "            if self.verbose:\n",
        "                print(\"player move, but not push:\", action)\n",
        "            return self._move(action), False\n",
        "\n",
        "    def _move(self, action):\n",
        "        \"\"\"\n",
        "        Moves the player to the next field, if it is not occupied.\n",
        "        :param action:\n",
        "        :return: Boolean, indicating a change of the room's state\n",
        "        \"\"\"\n",
        "        change = CHANGE_COORDINATES[(action - 1) % 4]\n",
        "        new_position = (self.player_position[0] + change[0], self.player_position[1] + change[1])\n",
        "        current_position = self.player_position\n",
        "\n",
        "        # Move player if the field in the moving direction is either\n",
        "        # an empty field or an empty box target.\n",
        "        if self.room_state[new_position[0], new_position[1]] in [1, 2]:\n",
        "            self.player_position = new_position\n",
        "            self.room_state[(new_position[0], new_position[1])] = 5\n",
        "            self.room_state[current_position[0], current_position[1]] = \\\n",
        "                self.room_fixed[current_position[0], current_position[1]]\n",
        "\n",
        "            # update player's recent positions, which are used for reward calculation\n",
        "            if len(self.player_recent_pos) > 5:\n",
        "                self.player_recent_pos.pop(0)\n",
        "            self.player_recent_pos.append(self.player_position)\n",
        "            return True\n",
        "        else:\n",
        "            if self.verbose:\n",
        "                print(\"player movement is invalid:\", action)\n",
        "\n",
        "        return False\n",
        "\n",
        "\n",
        "    def _check_if_done(self):\n",
        "        # Check if the game is over either through reaching the maximum number\n",
        "        # of available steps or by pushing all boxes on the targets.\n",
        "        self.fail = self.isFailed()\n",
        "        return self._check_if_all_boxes_on_target() or self._check_if_maxsteps() or self.fail\n",
        "\n",
        "    def _check_if_all_boxes_on_target(self):\n",
        "        empty_targets = self.room_state == 2\n",
        "        player_hiding_target = (self.room_fixed == 2) & (self.room_state == 5)\n",
        "        are_all_boxes_on_targets = np.where(empty_targets | player_hiding_target)[0].shape[0] == 0\n",
        "        return are_all_boxes_on_targets\n",
        "\n",
        "    def _check_if_maxsteps(self):\n",
        "        return (self.max_steps == self.num_env_steps)\n",
        "\n",
        "\n",
        "    def render(self, mode='raw', close=None, scale=1):\n",
        "        assert mode in RENDERING_MODES\n",
        "\n",
        "        img = self.get_image(mode, scale)\n",
        "\n",
        "        if 'rgb_array' in mode:\n",
        "            return img\n",
        "\n",
        "        elif 'human' in mode:\n",
        "            from gym.envs.classic_control import rendering\n",
        "            if self.viewer is None:\n",
        "                self.viewer = rendering.SimpleImageViewer()\n",
        "            self.viewer.imshow(img)\n",
        "            return self.viewer.isopen\n",
        "\n",
        "        elif 'raw' in mode:\n",
        "            arr_walls = (self.room_fixed == 0).view(np.int8)\n",
        "            arr_goals = (self.room_fixed == 2).view(np.int8)\n",
        "            arr_boxes = ((self.room_state == 4) + (self.room_state == 3)).view(np.int8)\n",
        "            arr_player = (self.room_state == 5).view(np.int8)\n",
        "\n",
        "            # fill in the empty box and target positions with zero\n",
        "            if len(self.boxes) < self.num_boxes:\n",
        "                symbolic_obs = np.concatenate([np.array(self.player_position).flatten(),\n",
        "                                               np.pad(np.array(self.boxes).flatten(), (0, 2*self.num_boxes - 2*len(self.boxes)), mode='constant'),\n",
        "                                               np.pad(np.array(self.targets).flatten(), (0, 2*self.num_boxes - 2*len(self.boxes)), mode='constant'),\n",
        "                                               arr_walls.flatten()])\n",
        "            else:\n",
        "                symbolic_obs = np.concatenate([np.array(self.player_position).flatten(), np.array(self.boxes).flatten(), np.array(self.targets).flatten(), arr_walls.flatten()])\n",
        "            return symbolic_obs\n",
        "\n",
        "        else:\n",
        "            if self.verbose:\n",
        "                print(\"generate error when rendering...\")  # just raise an exception\n",
        "            pass\n",
        "\n",
        "    def get_image(self, mode, scale=1):\n",
        "\n",
        "        if mode.startswith('tiny_'):\n",
        "            img = room_to_tiny_world_rgb(self.room_state, self.room_fixed, scale=scale)\n",
        "        else:\n",
        "            img = room_to_rgb(self.room_state, self.room_fixed)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def close(self):\n",
        "        if self.viewer is not None:\n",
        "            self.viewer.close()\n",
        "\n",
        "    def set_maxsteps(self, num_steps):\n",
        "        self.max_steps = num_steps\n",
        "\n",
        "    def get_action_lookup(self):\n",
        "        return PUSH_ACTION_LOOKUP\n",
        "\n",
        "    def get_action_meanings(self):\n",
        "        return PUSH_ACTION_LOOKUP\n",
        "\n",
        "\n",
        "    def step(self, action, observation_mode='raw'):\n",
        "        assert action in PUSH_ACTION_LOOKUP\n",
        "        assert observation_mode in ['rgb_array', 'tiny_rgb_array', 'raw']\n",
        "\n",
        "        self.num_env_steps += 1\n",
        "        self.new_box_position = None\n",
        "        self.old_box_position = None\n",
        "        self.invalid_action = False\n",
        "\n",
        "        moved_box = False\n",
        "\n",
        "        if action == 0:\n",
        "            moved_player = False\n",
        "            self.invalid_action = True\n",
        "            if self.verbose:\n",
        "                print(\"no action !!\")\n",
        "\n",
        "        # All push actions are in the range of [0, 3]\n",
        "        elif action < 5:\n",
        "            moved_player, moved_box = self._push(action)\n",
        "            if moved_player is False or moved_box is False:\n",
        "                self.invalid_action = True\n",
        "        else:\n",
        "            moved_player = self._move(action)\n",
        "            if moved_player is False:\n",
        "                self.invalid_action = True\n",
        "\n",
        "\n",
        "        # Convert the observation to RGB frame\n",
        "        image_observation = self.render(mode=\"rgb_array\")\n",
        "        observation = self.render(mode=observation_mode)\n",
        "        self.fail = self.isFailed()\n",
        "        self._calc_reward()\n",
        "        done = self._check_if_done()\n",
        "\n",
        "        info = {\n",
        "            \"action.name\": PUSH_ACTION_LOOKUP[action],\n",
        "            \"action.moved_player\": moved_player,\n",
        "            \"action.moved_box\": moved_box,\n",
        "            \"observation\": observation,\n",
        "            \"image_observation\": image_observation\n",
        "        }\n",
        "        if done:\n",
        "            info[\"maxsteps_used\"] = self._check_if_maxsteps()\n",
        "            info[\"success\"] = self._check_if_all_boxes_on_target()\n",
        "            info[\"num_steps\"] = self.num_env_steps\n",
        "            info['boxes_pos'] = self.boxes\n",
        "            info['player_pos'] = self.player_position\n",
        "            ## known issue: the last observation could not be captured by the callback function. an issue from stable_baselines3\n",
        "            # info[\"last_observation\"] = image_observation\n",
        "            info[\"last_observation\"] = image_observation\n",
        "\n",
        "        return observation, self.reward_last, done, info\n",
        "\n",
        "\n",
        "    def _calc_reward(self):\n",
        "\n",
        "        # Add step penalty to encourage efficiency\n",
        "        if self.invalid_action:\n",
        "            shaped_reward = self.penalty_for_step - 0.05\n",
        "        else:\n",
        "            shaped_reward = self.penalty_for_step\n",
        "\n",
        "        current_state = (self.boxes + [(self.player_position[0], self.player_position[1])])\n",
        "\n",
        "        if current_state not in self.visited_states:\n",
        "            # New state exploration bonus\n",
        "            shaped_reward += self.reward_exploration_bonus\n",
        "            self.visited_states.append(current_state)\n",
        "\n",
        "        # Reward for new boxes on target and then update self.boxes_on_target\n",
        "        box_on_target = len(set(self.targets).intersection(set(self.boxes)))\n",
        "        if box_on_target > self.boxes_on_target:\n",
        "            shaped_reward += self.reward_box_on_target\n",
        "        # Penalty for boxes moved off target\n",
        "        elif box_on_target < self.boxes_on_target:\n",
        "            shaped_reward -= self.reward_box_on_target\n",
        "        self.boxes_on_target = box_on_target\n",
        "\n",
        "        # Extra reward for solving the puzzle\n",
        "        if self._check_if_all_boxes_on_target():\n",
        "            shaped_reward += self.reward_puzzle_solved\n",
        "\n",
        "        # encourage player to visit different areas\n",
        "        self.player_position = tuple(self.player_position)\n",
        "        if self.player_position not in self.player_visited_pos:\n",
        "            shaped_reward += self.reward_player_explore\n",
        "            self.player_visited_pos.append(self.player_position)\n",
        "\n",
        "        # the last step in self.player_recent_pos is the player's position, so not compare with itself\n",
        "        if self.player_position in self.player_recent_pos[:-1]:\n",
        "            shaped_reward += self.penalty_repeat_walk_around\n",
        "\n",
        "        distances = 0\n",
        "        for box in self.boxes:\n",
        "            distance = min([manhattan_distance(box, target) for target in self.targets])\n",
        "            distances += distance\n",
        "        shaped_reward -= distances * 0.2\n",
        "\n",
        "        # penalizing not pushing box, and just moving around\n",
        "        if (self.num_env_steps - self.last_step_push_box) > 5:\n",
        "            shaped_reward -= 0.25\n",
        "\n",
        "        # Simple corner detection - penalty for pushing box into corner and early fail\n",
        "        if self.fail:\n",
        "            if self.verbose:\n",
        "                print(\"early dead!! box is pushed to dead end\")\n",
        "            shaped_reward += self.penalty_box_deadend - 50 /self.num_env_steps\n",
        "\n",
        "        self.reward_last = shaped_reward\n",
        "\n",
        "\n",
        "    # C: copied and edited from the original repo sokoban-solver-master, which explains this algorithm\n",
        "    def isFailed(self):\n",
        "        \"\"\"This function used to observe if the state is potentially failed, then prune the search\"\"\"\n",
        "\n",
        "        for box in self.boxes:\n",
        "            if box not in self.targets:\n",
        "\n",
        "                # check the condition around the box\n",
        "                board = [(box[0] - 1, box[1] - 1), (box[0] - 1, box[1]), (box[0] - 1, box[1] + 1),\n",
        "                (box[0], box[1] - 1), (box[0], box[1]), (box[0], box[1] + 1),\n",
        "                (box[0] + 1, box[1] - 1), (box[0] + 1, box[1]), (box[0] + 1, box[1] + 1)]\n",
        "\n",
        "                if self.verbose:\n",
        "                    print(\"board:\", board)\n",
        "                    print(board[1] in self.walls_pos, board[3] in self.walls_pos, board[5] in self.walls_pos, board[7] in self.walls_pos)\n",
        "                targets_x = [target[0] for target in self.targets]\n",
        "                targets_y = [target[1] for target in self.targets]\n",
        "\n",
        "                if (board[1] in self.walls_pos) and (board[5] in self.walls_pos): return True\n",
        "                elif (board[1] in self.walls_pos) and (board[3] in self.walls_pos): return True\n",
        "                elif (board[3] in self.walls_pos) and (board[7] in self.walls_pos): return True\n",
        "                elif (board[7] in self.walls_pos) and (board[5] in self.walls_pos): return True\n",
        "                elif (board[0] in self.walls_pos) and (board[1] in self.walls_pos) and board[2] in self.walls_pos and (box[0] not in targets_x): return True\n",
        "                elif (board[0] in self.walls_pos) and (board[3] in self.walls_pos) and board[6] in self.walls_pos and (box[1] not in targets_y): return True\n",
        "                elif (board[2] in self.walls_pos) and (board[5] in self.walls_pos) and board[8] in self.walls_pos and (box[1] not in targets_y): return True\n",
        "                elif (board[6] in self.walls_pos) and (board[7] in self.walls_pos) and board[8] in self.walls_pos and (box[0] not in targets_x): return True\n",
        "\n",
        "        return False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3kzBRHgz3UL"
      },
      "outputs": [],
      "source": [
        "\n",
        "class TestSokobanEnv(CustomizeSokobanEnv):\n",
        "    def __init__(self, start_level = 1, end_level = None, *args, **kwargs):\n",
        "\n",
        "        self.start_level = start_level\n",
        "        self.current_level = start_level\n",
        "        if end_level is None:\n",
        "            self.end_level = 8\n",
        "        else:\n",
        "            self.end_level = end_level\n",
        "        self.training_done = False\n",
        "        self.map_filename = None\n",
        "\n",
        "        # Call the parent constructor with all remaining args/kwargs\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "\n",
        "    # C: Either choose to download sokoban levels and randomly choose one layout or choose to generate onsite\n",
        "    def reset(self, mode=\"curriculum\", curriculum_level = 1):\n",
        "        self.num_env_steps = 0\n",
        "        self.reward_last = 0\n",
        "        self.boxes_on_target = self.num_boxes\n",
        "        self.box_distances = -1\n",
        "        self.visited_states = []\n",
        "        self.player_recent_pos = []\n",
        "        self.solution = None\n",
        "        self.current_level = curriculum_level\n",
        "\n",
        "        if mode == \"import\":\n",
        "            self.train_data_dir = os.path.join(self.cache_path, 'boxoban-levels-master', self.difficulty, self.split)\n",
        "\n",
        "            if not os.path.exists(self.train_data_dir):\n",
        "                if not os.path.exists(self.cache_path):\n",
        "                    os.makedirs(self.cache_path)\n",
        "\n",
        "                url = \"https://github.com/deepmind/boxoban-levels/archive/master.zip\"\n",
        "\n",
        "                if self.verbose:\n",
        "                    print('Boxoban: Pregenerated levels not downloaded.')\n",
        "                    print('Starting download from \"{}\"'.format(url))\n",
        "\n",
        "                response = requests.get(url, stream=True)\n",
        "\n",
        "                if response.status_code != 200:\n",
        "                    raise \"Could not download levels from {}. If this problem occurs consistantly please report the bug under https://github.com/mpSchrader/gym-sokoban/issues. \".format(url)\n",
        "\n",
        "                # download the sokoban levels from github and store them in the path, unzip the file\n",
        "                path_to_zip_file = os.path.join(self.cache_path, 'boxoban_levels-master.zip')\n",
        "                with open(path_to_zip_file, 'wb') as handle:\n",
        "                    for data in tqdm(response.iter_content()):\n",
        "                        handle.write(data)\n",
        "\n",
        "                zip_ref = zipfile.ZipFile(path_to_zip_file, 'r')\n",
        "                zip_ref.extractall(self.cache_path)\n",
        "                zip_ref.close()\n",
        "\n",
        "            self.select_room()\n",
        "        elif mode == \"curriculum\":\n",
        "\n",
        "            self.train_data_dir = os.path.join(base_dir, 'human_demos')\n",
        "            self.selected_map, solution, map_filename = choose_map(self.train_data_dir, self.current_level)\n",
        "            self.room_fixed, self.room_state, self.box_mapping = self.import_generate_room(self.selected_map)\n",
        "            self.solution = solution\n",
        "            logging.info(f\"Choose map file name {map_filename}\")\n",
        "\n",
        "        elif mode == \"generate\":\n",
        "            render_mode=\"raw\"\n",
        "            try:\n",
        "                # use room_utils.generate_room\n",
        "                self.room_fixed, self.room_state, self.box_mapping = room_utils.generate_room(\n",
        "                    dim=self.dim_room,\n",
        "                    num_steps=self.num_gen_steps,\n",
        "                    num_boxes=self.num_boxes,\n",
        "                    second_player=False\n",
        "                )\n",
        "            except (RuntimeError, RuntimeWarning) as e:\n",
        "                if self.verbose:\n",
        "                    print(\"[SOKOBAN] Runtime Error/Warning: {}\".format(e))\n",
        "                    print(\"[SOKOBAN] Retry . . .\")\n",
        "                # return self.reset(second_player=False, render_mode=render_mode)\n",
        "\n",
        "        # for those target positions, set the type to 3 (target and box are at the same place)\n",
        "        # for those box positions, set the type from 4 to 1 (become empty floor)\n",
        "        self.player_position = np.argwhere(self.room_state == 5)[0]\n",
        "        render_mode=\"raw\"\n",
        "        starting_observation = self.render(mode = render_mode)\n",
        "        return starting_observation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKw9CW3FKBLp"
      },
      "source": [
        "## Pull sokoban env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IR7WUzPoagGV"
      },
      "outputs": [],
      "source": [
        "from gym_sokoban.envs.sokoban_env import SokobanEnv, CHANGE_COORDINATES\n",
        "\n",
        "from gym.spaces import Box\n",
        "from gym.spaces.discrete import Discrete\n",
        "from gym_sokoban.envs.room_utils import generate_room\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# C: this is for backward behavior\n",
        "class PullSokobanEnv(SokobanEnv):\n",
        "\n",
        "    def __init__(self,\n",
        "                 dim_room=(10, 10),\n",
        "                 max_steps=120,\n",
        "                 num_boxes=3,\n",
        "                 num_gen_steps=None,\n",
        "                 verbose=False,\n",
        "                 difficulty =\"medium\",\n",
        "                 split =\"train\",\n",
        "                 reset = False):\n",
        "\n",
        "        super().__init__(dim_room, max_steps, num_boxes, num_gen_steps, verbose)\n",
        "        # screen_height, screen_width = (dim_room[0] * 16, dim_room[1] * 16)\n",
        "\n",
        "        self.boxes_are_on_target = [True] * num_boxes\n",
        "        self.action_space = Discrete(len(PULL_ACTION_LOOKUP))\n",
        "\n",
        "        # Penalties and Rewards for reverse Sokoban\n",
        "        # Define reward values - adjusted for better learning\n",
        "        self.reward_box_on_target = 2.0     # Increase (was 5.0)\n",
        "        self.reward_box_closer = 0.2         # Increase (was 0.5)\n",
        "        self.reward_puzzle_solved = 10.0     # Larger reward for solving\n",
        "        self.reward_exploration_bonus = 0.25       # Small bonus for trying new states\n",
        "        self.reward_player_explore = 0.2\n",
        "        self.reward_box_closer = 0.2\n",
        "\n",
        "        self.penalty_box_deadend = -10    # Penalty for corner situations\n",
        "        self.penalty_for_step = -0.05          # Reduce (was -0.001)\n",
        "        self.penalty_repeat_walk_around = -0.2\n",
        "\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.difficulty = difficulty\n",
        "        self.split =  split\n",
        "        self.invalid_action = False\n",
        "\n",
        "        self.cache_path = base_dir + \"/.sokoban_cache\"\n",
        "        self.selected_map = None\n",
        "        self.verbose = verbose\n",
        "        self.visited_states = []\n",
        "        self.player_visited_pos = []\n",
        "        self.player_recent_pos =[]\n",
        "        self.last_step_pull_box = -1\n",
        "        # Define symbolic observation space: player (x,y) + each box (x,y)\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0,\n",
        "            high=self.dim_room[0],\n",
        "            shape=(2 + 4 * self.num_boxes + self.dim_room[0] * self.dim_room[1],),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "        if reset:\n",
        "            self.reset()\n",
        "\n",
        "    def _check_if_all_boxes_off_target(self):\n",
        "        are_all_boxes_off_targets = self.boxes_on_target == 0\n",
        "        return are_all_boxes_off_targets\n",
        "\n",
        "\n",
        "# C: Either choose to download sokoban levels and randomly choose one layout or choose to generate onsite\n",
        "    def reset(self, mode=\"curriculum\", curriculum_level = 1):\n",
        "        self.num_env_steps = 0\n",
        "        self.reward_last = 0\n",
        "        self.boxes_on_target = self.num_boxes\n",
        "        self.box_distances = -1\n",
        "        self.visited_states = []\n",
        "        self.player_recent_pos = []\n",
        "        self.solution = None\n",
        "        self.current_level = curriculum_level\n",
        "        self.last_step_pull_box = -1\n",
        "\n",
        "        if mode == \"import\":\n",
        "            self.train_data_dir = os.path.join(self.cache_path, 'boxoban-levels-master', self.difficulty, self.split)\n",
        "\n",
        "            if not os.path.exists(self.train_data_dir):\n",
        "                if not os.path.exists(self.cache_path):\n",
        "                    os.makedirs(self.cache_path)\n",
        "\n",
        "                url = \"https://github.com/deepmind/boxoban-levels/archive/master.zip\"\n",
        "\n",
        "                if self.verbose:\n",
        "                    print('Boxoban: Pregenerated levels not downloaded.')\n",
        "                    print('Starting download from \"{}\"'.format(url))\n",
        "\n",
        "                response = requests.get(url, stream=True)\n",
        "\n",
        "                if response.status_code != 200:\n",
        "                    raise \"Could not download levels from {}. If this problem occurs consistantly please report the bug under https://github.com/mpSchrader/gym-sokoban/issues. \".format(url)\n",
        "\n",
        "                # download the sokoban levels from github and store them in the path, unzip the file\n",
        "                path_to_zip_file = os.path.join(self.cache_path, 'boxoban_levels-master.zip')\n",
        "                with open(path_to_zip_file, 'wb') as handle:\n",
        "                    for data in tqdm(response.iter_content()):\n",
        "                        handle.write(data)\n",
        "\n",
        "                zip_ref = zipfile.ZipFile(path_to_zip_file, 'r')\n",
        "                zip_ref.extractall(self.cache_path)\n",
        "                zip_ref.close()\n",
        "\n",
        "            self.select_room()\n",
        "        elif mode == \"curriculum\":\n",
        "\n",
        "\n",
        "            self.train_data_dir = os.path.join(base_dir, 'human_demos')\n",
        "            self.selected_map, solution, map_filename = choose_map(self.train_data_dir, self.current_level)\n",
        "            self.room_fixed, self.room_state, self.box_mapping = self.import_generate_room(self.selected_map)\n",
        "            self.solution = solution\n",
        "            logging.info(f\"Choose map file name {map_filename}\")\n",
        "\n",
        "        elif mode == \"generate\":\n",
        "            # render_mode='rgb_array'\n",
        "            render_mode=\"raw\"\n",
        "            try:\n",
        "                # use room_utils.generate_room\n",
        "                self.room_fixed, self.room_state, self.box_mapping = room_utils.generate_room(\n",
        "                    dim=self.dim_room,\n",
        "                    num_steps=self.num_gen_steps,\n",
        "                    num_boxes=self.num_boxes,\n",
        "                    second_player=False\n",
        "                )\n",
        "            except (RuntimeError, RuntimeWarning) as e:\n",
        "                if self.verbose:\n",
        "                    print(\"[SOKOBAN] Runtime Error/Warning: {}\".format(e))\n",
        "                    print(\"[SOKOBAN] Retry . . .\")\n",
        "\n",
        "        # Change target into boxes on target and boxes into empty space\n",
        "        # for those target positions, set the type to 3 (target and box are at the same place)\n",
        "        # for those box positions, set the type from 4 to 1 (become empty floor)\n",
        "        self.player_position = np.argwhere(self.room_state == 5)[0]\n",
        "        self.room_state[self.room_state == 2] = 3\n",
        "        self.room_state[self.room_state == 4] = 1\n",
        "        # symbolic_obs = np.concatenate([np.array(self.player_position), np.array(self.boxes).flatten()])\n",
        "        render_mode=\"raw\"\n",
        "        starting_observation = self.render(mode = render_mode)\n",
        "\n",
        "        # print(\"starting observation:\", starting_observation)\n",
        "        return starting_observation\n",
        "\n",
        "    # used when mode  == \"import\"\n",
        "    def select_room(self):\n",
        "\n",
        "        # C: since the downloaded sokoban levels are located in nested directory, use this to get all the files and store in list generated_files\n",
        "        generated_files = [f for f in listdir(self.train_data_dir) if isfile(join(self.train_data_dir, f))]\n",
        "        source_file = join(self.train_data_dir, random.choice(generated_files))\n",
        "\n",
        "        # C: pay attention that each source_file contains multiple sokoban layout maps\n",
        "        maps = []\n",
        "        current_map = []\n",
        "\n",
        "        with open(source_file, 'r') as sf:\n",
        "            for line in sf.readlines():\n",
        "                # C: read text file one by one. If the current line contains ; then one map is finished\n",
        "                if ';' in line and current_map:\n",
        "                    maps.append(current_map)\n",
        "                    current_map = []\n",
        "                if '#' == line[0]:          # if the current line contains # which represents wall, then continue add this line as current map\n",
        "                    current_map.append(line.strip())\n",
        "\n",
        "        maps.append(current_map)\n",
        "\n",
        "        self.selected_map = random.choice(maps)\n",
        "\n",
        "        if self.verbose:\n",
        "            print('Selected Level from File \"{}\"'.format(source_file))\n",
        "        self.room_fixed, self.room_state, self.box_mapping = self.import_generate_room(self.selected_map)\n",
        "\n",
        "\n",
        "    def import_generate_room(self, select_map):\n",
        "        room_fixed = []\n",
        "        room_state = []\n",
        "\n",
        "        '''\n",
        "        Generates a Sokoban room, represented by an integer matrix. The elements are encoded as follows:\n",
        "        wall = 0\n",
        "        empty space = 1\n",
        "        box target = 2\n",
        "        box not on target = 4\n",
        "\n",
        "        player = 5\n",
        "        '''\n",
        "        self.targets = []\n",
        "        self.boxes = []\n",
        "        self.walls_pos = []\n",
        "        for row in select_map:\n",
        "            room_f = []\n",
        "            room_s = []\n",
        "\n",
        "            for e in row:\n",
        "                if e == '#':\n",
        "                    self.walls_pos.append((len(room_fixed), len(room_f)))\n",
        "                    room_f.append(0)\n",
        "                    room_s.append(0)\n",
        "\n",
        "                elif e == '@':\n",
        "                    # C: @ represent player position\n",
        "                    # C: len(room_fixed) represents the row index (starting from 1), len(room_f) represents the column index (starting from 1)\n",
        "                    self.player_position = (len(room_fixed), len(room_f))\n",
        "                    room_f.append(1)\n",
        "                    room_s.append(5)\n",
        "\n",
        "                # represent box\n",
        "                elif e == '$':\n",
        "                    self.boxes.append((len(room_fixed), len(room_f)))\n",
        "                    room_f.append(1)\n",
        "                    room_s.append(4)\n",
        "\n",
        "                # C: represent box target\n",
        "                elif e == '.':\n",
        "                    self.targets.append((len(room_fixed), len(room_f)))\n",
        "                    room_f.append(2)\n",
        "                    room_s.append(2)\n",
        "                elif e == '*':\n",
        "                    # targets\n",
        "                    self.targets.append((len(room_fixed), len(room_f)))\n",
        "                    room_f.append(2)\n",
        "                    room_s.append(2)\n",
        "\n",
        "                    # box\n",
        "                    self.boxes.append((len(room_fixed), len(room_f)))\n",
        "                    room_f.append(1)\n",
        "                    room_s.append(4)\n",
        "\n",
        "                else:\n",
        "                    room_f.append(1)\n",
        "                    room_s.append(1)\n",
        "\n",
        "            # room_f represents all those room elements, wall, player, box, box targets. They are represented by different number\n",
        "            room_fixed.append(room_f)\n",
        "            room_state.append(room_s)\n",
        "\n",
        "        # the initial boxes and player position. Store them to be used in reward calculation\n",
        "        self.visited_states.append((self.boxes + [(self.player_position[0], self.player_position[1])]))\n",
        "        if self.verbose:\n",
        "            print(\"after resetting and generate new room, \")\n",
        "            print(\"wall pos:\", self.walls_pos)\n",
        "            print(\"box pos:\", self.boxes)\n",
        "            print(\"target pos:\", self.targets)\n",
        "            print(\"player pos:\", self.player_position)\n",
        "        # used for replay in room generation, unused here because pre-generated levels\n",
        "        box_mapping = {}\n",
        "\n",
        "        return np.array(room_fixed), np.array(room_state), box_mapping\n",
        "\n",
        "    def render(self, mode='raw', close=None, scale=1):\n",
        "        assert mode in RENDERING_MODES\n",
        "\n",
        "        img = self.get_image(mode, scale)\n",
        "\n",
        "        if 'rgb_array' in mode:\n",
        "            return img\n",
        "\n",
        "        elif 'human' in mode:\n",
        "            from gym.envs.classic_control import rendering\n",
        "            if self.viewer is None:\n",
        "                self.viewer = rendering.SimpleImageViewer()\n",
        "            self.viewer.imshow(img)\n",
        "            return self.viewer.isopen\n",
        "\n",
        "        elif 'raw' in mode:\n",
        "            arr_walls = (self.room_fixed == 0).view(np.int8)\n",
        "            arr_goals = (self.room_fixed == 2).view(np.int8)\n",
        "            arr_boxes = ((self.room_state == 4) + (self.room_state == 3)).view(np.int8)\n",
        "            arr_player = (self.room_state == 5).view(np.int8)\n",
        "\n",
        "            if len(self.boxes) < self.num_boxes:\n",
        "                symbolic_obs = np.concatenate([np.array(self.player_position).flatten(),\n",
        "                                               np.pad(np.array(self.boxes).flatten(), (0, 2*self.num_boxes - 2*len(self.boxes)), mode='constant'),\n",
        "                                               np.pad(np.array(self.targets).flatten(), (0, 2*self.num_boxes - 2*len(self.boxes)), mode='constant'),\n",
        "                                               arr_walls.flatten()])\n",
        "            else:\n",
        "                symbolic_obs = np.concatenate([np.array(self.player_position).flatten(), np.array(self.boxes).flatten(), np.array(self.targets).flatten(), arr_walls.flatten()])\n",
        "            return symbolic_obs\n",
        "\n",
        "        else:\n",
        "            if self.verbose:\n",
        "                print(\"generate error when rendering...\")  # just raise an exception\n",
        "            pass\n",
        "\n",
        "\n",
        "    def _check_if_done(self):\n",
        "        # Check if the game is over either through reaching the maximum number\n",
        "        # of available steps or by pushing all boxes on the targets.\n",
        "        return self._check_if_maxsteps() or self._check_if_all_boxes_off_target()    # need to check early finish condition later $$$$$$$$$\n",
        "\n",
        "\n",
        "    def step(self, action, observation_mode='raw'):\n",
        "\n",
        "        assert action in PULL_ACTION_LOOKUP\n",
        "\n",
        "        self.num_env_steps += 1\n",
        "\n",
        "        self.new_box_position = None\n",
        "        self.old_box_position = None\n",
        "        self.invalid_action = False\n",
        "\n",
        "        moved_box = False\n",
        "        if action == 0:\n",
        "            moved_player = False\n",
        "            self.invalid_action = True\n",
        "\n",
        "        # All pull actions are in the range of [0, 3]\n",
        "        if action < 5:\n",
        "            moved_player, moved_box = self._pull(action)\n",
        "            if moved_player is False or moved_box is False:\n",
        "                self.invalid_action = True\n",
        "        else:\n",
        "            moved_player = self._move(action)\n",
        "            if moved_player is False:\n",
        "                self.invalid_action = True\n",
        "\n",
        "        self._calc_reward()\n",
        "\n",
        "        done = self._check_if_done()\n",
        "\n",
        "        # Convert the observation to RGB frame\n",
        "        observation = self.render(mode=observation_mode)\n",
        "\n",
        "        info = {\n",
        "            \"action.name\": PULL_ACTION_LOOKUP[action],\n",
        "            \"action.moved_player\": moved_player,\n",
        "            \"action.moved_box\": moved_box,\n",
        "        }\n",
        "        if done:\n",
        "            info[\"maxsteps_used\"] = self._check_if_maxsteps()\n",
        "            info[\"all_boxes_on_target\"] = self._check_if_all_boxes_on_target()\n",
        "\n",
        "        return observation, self.reward_last, done, info\n",
        "\n",
        "\n",
        "    def _pull(self, action):\n",
        "        \"\"\"\n",
        "        Perform a push, if a box is adjacent in the right direction.\n",
        "        If no box, can be pushed, try to move.\n",
        "        :param action:\n",
        "        :return: Boolean, indicating a change of the room's state\n",
        "        \"\"\"\n",
        "        change = CHANGE_COORDINATES[(action - 1) % 4]\n",
        "        new_player_position = (self.player_position[0] + change[0], self.player_position[1] + change[1])\n",
        "        old_box_position = (self.player_position[0] - change[0], self.player_position[1] - change[1])\n",
        "        current_player_position = self.player_position\n",
        "\n",
        "\n",
        "\n",
        "        # No push, if the push would get the box out of the room's grid\n",
        "        new_box_position = (new_player_position[0] + change[0], new_player_position[1] + change[1])\n",
        "        new_box_position = current_player_position\n",
        "        if new_player_position[0] >= self.room_state.shape[0] \\\n",
        "                or new_player_position[0] < 0 \\\n",
        "                or new_player_position[1] >= self.room_state.shape[1] \\\n",
        "                or new_player_position[1] < 0:\n",
        "            return False, False\n",
        "\n",
        "        can_pull_box = self.room_state[(current_player_position[0], current_player_position[1])] in [3, 4]\n",
        "        can_pull_box &= self.room_state[(new_player_position[0], new_player_position[1])] in [1, 2]\n",
        "        if can_pull_box:\n",
        "\n",
        "            # self.room_state records each position's type: wall = 0, empty space = 1, box target = 2, box not on target = 4, player = 5\n",
        "            # Move Player\n",
        "            self.player_position = new_player_position\n",
        "            self.room_state[new_player_position] = 5\n",
        "            self.room_state[old_box_position] = \\\n",
        "                self.room_fixed[old_box_position]\n",
        "\n",
        "            # Move Box\n",
        "            box_type = 4\n",
        "            if self.room_fixed[new_box_position] == 2:\n",
        "                box_type = 3\n",
        "            self.room_state[new_box_position[0], new_box_position[1]] = box_type\n",
        "\n",
        "            # update boxes position and sort - prepare for reward calculation\n",
        "            self.boxes = [box for box in self.boxes if not (box[0] == self.player_position[0] and box[1] == self.player_position[1])]\n",
        "            self.boxes.append(new_box_position)\n",
        "            self.boxes.sort()\n",
        "            self.last_step_pull_box = self.num_env_steps\n",
        "\n",
        "            if len(self.player_recent_pos) > 5:\n",
        "                self.player_recent_pos.pop(0)\n",
        "            self.player_recent_pos.append(self.player_position)\n",
        "            return True, True\n",
        "\n",
        "        # Try to move if no box to pull, available\n",
        "        else:\n",
        "            if self.verbose:\n",
        "                print(\"player move, but not push:\", action)\n",
        "            return self._move(action), False\n",
        "\n",
        "    def _move(self, action):\n",
        "        \"\"\"\n",
        "        Moves the player to the next field, if it is not occupied.\n",
        "        :param action:\n",
        "        :return: Boolean, indicating a change of the room's state\n",
        "        \"\"\"\n",
        "        change = CHANGE_COORDINATES[(action - 1) % 4]\n",
        "        new_position = (self.player_position[0] + change[0], self.player_position[1] + change[1])\n",
        "        current_position = self.player_position\n",
        "\n",
        "        # Move player if the field in the moving direction is either\n",
        "        # an empty field or an empty box target.\n",
        "        if self.room_state[new_position] in [1, 2]:\n",
        "            self.player_position = new_position\n",
        "            self.room_state[new_position] = 5\n",
        "            self.room_state[current_position] = \\\n",
        "                self.room_fixed[current_position]\n",
        "\n",
        "            # update player's recent positions, which are used for reward calculation\n",
        "            if len(self.player_recent_pos) > 5:\n",
        "                self.player_recent_pos.pop(0)\n",
        "            self.player_recent_pos.append(self.player_position)\n",
        "            return True\n",
        "        else:\n",
        "            if self.verbose:\n",
        "                print(\"player movement is invalid:\", action)\n",
        "\n",
        "        return False\n",
        "\n",
        "\n",
        "    def _check_if_done(self):\n",
        "        # Check if the game is over either through reaching the maximum number\n",
        "        # of available steps or by pushing all boxes on the targets.\n",
        "        return self._check_if_all_boxes_off_target() or self._check_if_maxsteps()\n",
        "\n",
        "    def _check_if_maxsteps(self):\n",
        "        return (self.max_steps == self.num_env_steps)\n",
        "\n",
        "\n",
        "    def render(self, mode='raw', close=None, scale=1):\n",
        "        assert mode in RENDERING_MODES\n",
        "\n",
        "        img = self.get_image(mode, scale)\n",
        "\n",
        "        if 'rgb_array' in mode:\n",
        "            return img\n",
        "\n",
        "        elif 'human' in mode:\n",
        "            from gym.envs.classic_control import rendering\n",
        "            if self.viewer is None:\n",
        "                self.viewer = rendering.SimpleImageViewer()\n",
        "            self.viewer.imshow(img)\n",
        "            return self.viewer.isopen\n",
        "\n",
        "        elif 'raw' in mode:\n",
        "            arr_walls = (self.room_fixed == 0).view(np.int8)\n",
        "            arr_goals = (self.room_fixed == 2).view(np.int8)\n",
        "            arr_boxes = ((self.room_state == 4) + (self.room_state == 3)).view(np.int8)\n",
        "            arr_player = (self.room_state == 5).view(np.int8)\n",
        "\n",
        "            if len(self.boxes) < self.num_boxes:\n",
        "                symbolic_obs = np.concatenate([np.array(self.player_position).flatten(),\n",
        "                                               np.pad(np.array(self.boxes).flatten(), (0, 2*self.num_boxes - 2*len(self.boxes)), mode='constant'),\n",
        "                                               np.pad(np.array(self.targets).flatten(), (0, 2*self.num_boxes - 2*len(self.boxes)), mode='constant'),\n",
        "                                               arr_walls.flatten()])\n",
        "            else:\n",
        "                symbolic_obs = np.concatenate([np.array(self.player_position).flatten(), np.array(self.boxes).flatten(), np.array(self.targets).flatten(), arr_walls.flatten()])\n",
        "            return symbolic_obs\n",
        "\n",
        "        else:\n",
        "            if self.verbose:\n",
        "                print(\"generate error when rendering...\")  # just raise an exception\n",
        "            pass\n",
        "\n",
        "    def get_image(self, mode, scale=1):\n",
        "\n",
        "        if mode.startswith('tiny_'):\n",
        "            img = room_to_tiny_world_rgb(self.room_state, self.room_fixed, scale=scale)\n",
        "        else:\n",
        "            img = room_to_rgb(self.room_state, self.room_fixed)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def close(self):\n",
        "        if self.viewer is not None:\n",
        "            self.viewer.close()\n",
        "\n",
        "    def set_maxsteps(self, num_steps):\n",
        "        self.max_steps = num_steps\n",
        "\n",
        "    def get_action_lookup(self):\n",
        "        return PULL_ACTION_LOOKUP\n",
        "\n",
        "    def get_action_meanings(self):\n",
        "        return PULL_ACTION_LOOKUP\n",
        "\n",
        "\n",
        "    def step(self, action, observation_mode='raw'):\n",
        "        assert action in sokoban_env.ACTION_LOOKUP\n",
        "        assert observation_mode in ['rgb_array', 'tiny_rgb_array', 'raw']\n",
        "\n",
        "        self.num_env_steps += 1\n",
        "        self.new_box_position = None\n",
        "        self.old_box_position = None\n",
        "        self.invalid_action = False\n",
        "        moved_box = False\n",
        "\n",
        "        if action == 0:\n",
        "            moved_player = False\n",
        "            self.invalid_action = True\n",
        "            if self.verbose:\n",
        "                print(\"no action !!\")\n",
        "\n",
        "        # All push actions are in the range of [1, 4]\n",
        "        elif action < 5:\n",
        "            moved_player, moved_box = self._pull(action)\n",
        "            if moved_player is False:\n",
        "                self.invalid_action = True\n",
        "\n",
        "        else:\n",
        "            moved_player = self._move(action)\n",
        "            if moved_player is False:\n",
        "                self.invalid_action = True\n",
        "\n",
        "\n",
        "        # Convert the observation to RGB frame\n",
        "        image_observation = self.render(mode=\"rgb_array\")\n",
        "        observation = self.render(mode=observation_mode)\n",
        "        self._calc_reward()\n",
        "        done = self._check_if_done()\n",
        "\n",
        "        info = {\n",
        "            \"action.name\": PULL_ACTION_LOOKUP[action],\n",
        "            \"action.moved_player\": moved_player,\n",
        "            \"action.moved_box\": moved_box,\n",
        "            \"observation\": observation,\n",
        "            \"image_observation\": image_observation\n",
        "        }\n",
        "        if done:\n",
        "            info[\"maxsteps_used\"] = self._check_if_maxsteps()\n",
        "            info[\"success\"] = self._check_if_all_boxes_on_target()\n",
        "            info[\"num_steps\"] = self.num_env_steps\n",
        "            info['boxes_pos'] = self.boxes\n",
        "            info['player_pos'] = self.player_position\n",
        "            ## known issue: the last observation could not be captured by the callback function. an issue from stable_baselines3\n",
        "            info[\"last_observation\"] = image_observation\n",
        "        return observation, self.reward_last, done, info\n",
        "\n",
        "\n",
        "    def _calc_reward(self):\n",
        "\n",
        "        # Add step penalty to encourage efficiency\n",
        "        if self.invalid_action:\n",
        "            shaped_reward = self.penalty_for_step - 0.05\n",
        "        else:\n",
        "            shaped_reward = self.penalty_for_step\n",
        "\n",
        "        current_state = (self.boxes + [(self.player_position[0], self.player_position[1])])\n",
        "        if current_state not in self.visited_states:\n",
        "            # New state exploration bonus\n",
        "            shaped_reward += self.reward_exploration_bonus\n",
        "            self.visited_states.append(current_state)\n",
        "\n",
        "\n",
        "        # encourage player to visit different areas\n",
        "        self.player_position = tuple(self.player_position)\n",
        "        if self.player_position not in self.player_visited_pos:\n",
        "            shaped_reward += self.reward_player_explore\n",
        "            self.player_visited_pos.append(self.player_position)\n",
        "\n",
        "        # the last step in self.player_recent_pos is the player's position, so not compare with itself\n",
        "        if self.player_position in self.player_recent_pos[:-1]:\n",
        "            shaped_reward += self.penalty_repeat_walk_around\n",
        "\n",
        "        distances = 0\n",
        "        for box in self.boxes:\n",
        "            distance = min([manhattan_distance(box, target) for target in self.targets])\n",
        "            distances += distance\n",
        "        shaped_reward += distances * 0.2\n",
        "\n",
        "        # penalizing not pushing box, and just moving around\n",
        "        if (self.num_env_steps - self.last_step_pull_box) > 5:\n",
        "            shaped_reward -= 0.2\n",
        "\n",
        "        # Simple corner detection - penalty for pushing box into corner and early fail\n",
        "        shaped_reward += self.penalty_box_deadend - 50 /self.num_env_steps\n",
        "\n",
        "        self.reward_last = shaped_reward\n",
        "\n",
        "\n",
        "PULL_ACTION_LOOKUP = {\n",
        "    0: 'no operation',\n",
        "    1: 'pull up',\n",
        "    2: 'pull down',\n",
        "    3: 'pull left',\n",
        "    4: 'pull right',\n",
        "    5: 'move up',\n",
        "    6: 'move down',\n",
        "    7: 'move left',\n",
        "    8: 'move right',\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvRWYE1rq0iM"
      },
      "source": [
        "## callback, train, display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEcOKvrTz3UL"
      },
      "source": [
        "### pygame real-time display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Rg_pIvAjwgjE"
      },
      "outputs": [],
      "source": [
        "import pygame\n",
        "import time\n",
        "def pygame_replay_training_episode(images_data, success, maxsteps_used):\n",
        "\n",
        "    # The following is to show training images with pygame. It will show after training total_timesteps finishes\n",
        "    pygame.init()\n",
        "\n",
        "    # Set up the display window (adjust for your image size)\n",
        "    width, height = 240, 240\n",
        "    screen = pygame.display.set_mode((width, height))\n",
        "\n",
        "    running = True\n",
        "    total_len = len(images_data)\n",
        "    i = 0\n",
        "    while running:\n",
        "        for event in pygame.event.get():\n",
        "            if event.type == pygame.QUIT:  # If the user closes the window\n",
        "                running = False\n",
        "\n",
        "        image = np.transpose(images_data[i], (1, 2, 0))  # Reorder to (height, width, channels)\n",
        "\n",
        "        # Create a pygame surface from the numpy array\n",
        "        surface = pygame.surfarray.make_surface(image)\n",
        "        scaled_surface = pygame.transform.scale(surface, (width, height))\n",
        "        screen.blit(scaled_surface, (0, 0))\n",
        "\n",
        "        i += 1\n",
        "        if i == total_len-1:\n",
        "            font = pygame.font.SysFont(None, 36)\n",
        "            if success is True:\n",
        "                text_surface = font.render(\"Success!\", True, (255, 255, 255))  # White text\n",
        "            else:\n",
        "                if maxsteps_used:\n",
        "                    text_surface = font.render(\"Fail! max_steps\", True, (255, 255, 255))  # White text\n",
        "                else:\n",
        "                    text_surface = font.render(\"Fail! push to corner\", True, (255, 255, 255))  # White text\n",
        "            screen.blit(text_surface, (20,20))\n",
        "\n",
        "        pygame.display.flip()  # Update the display\n",
        "\n",
        "        # Simulate time step delay to control the frame rate\n",
        "        pygame.time.wait(30)  # Adjust the wait time for desired speed\n",
        "        if i>= total_len-1:\n",
        "            running = False\n",
        "            time.sleep(2)\n",
        "\n",
        "\n",
        "    # Quit pygame when done\n",
        "    pygame.quit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LQ7cIFWcwgjE"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "from IPython.display import clear_output\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pngR5Tzmz3UM"
      },
      "source": [
        "### define real-time chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "azzD-Rjez3UM",
        "outputId": "c8fb901f-d16a-41ea-e12c-448d0b30c17d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "def exponential_smoothing(data, alpha=0.1):\n",
        "    \"\"\"Compute exponential smoothing.\"\"\"\n",
        "    smoothed = [data[0]]  # Initialize with the first data point\n",
        "    for i in range(1, len(data)):\n",
        "        st = alpha * data[i] + (1 - alpha) * smoothed[-1]\n",
        "        smoothed.append(st)\n",
        "    return smoothed\n",
        "\n",
        "def live_plot(data_dict, ylabel=\"Total Rewards\"):\n",
        "    \"\"\"Plot the live graph.\"\"\"\n",
        "    clear_output(wait=True)\n",
        "    ax.clear()\n",
        "    for label, data in data_dict.items():\n",
        "        if label == \"Total Reward\":\n",
        "            ax.plot(data, label=label, color=\"yellow\", linestyle='--')\n",
        "\n",
        "            # Compute and plot moving average for total reward\n",
        "            ma = exponential_smoothing(data)\n",
        "            ma_idx_start = len(data) - len(ma)\n",
        "            ax.plot(range(ma_idx_start, len(data)), ma, label=\"Smoothed Value\", linestyle=\"-\", color=\"purple\", linewidth=2)\n",
        "        else:\n",
        "            ax.plot(data, label=label)\n",
        "    ax.set_ylabel(ylabel)\n",
        "    ax.legend(loc='upper left')\n",
        "    display(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HKZzD28z3UM"
      },
      "source": [
        "### train, logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rjboLPlAVz5"
      },
      "source": [
        "### clean up the home folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCvRB3yiAVn6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKwH47rQqyNk",
        "outputId": "1b13307a-6e09-4b74-d2cc-c49aaef5a63a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rm: cannot remove '*.gif': No such file or directory\n",
            "rm: cannot remove '*.txt': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "import gym_sokoban\n",
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "import numpy as np\n",
        "from stable_baselines3.common.callbacks import BaseCallback\n",
        "import time\n",
        "import logging\n",
        "import imageio\n",
        "import pygame\n",
        "\n",
        "!rm *.gif\n",
        "!rm *.txt\n",
        "\n",
        "# Remove all existing handlers (especially from Jupyter)\n",
        "for handler in logging.root.handlers[:]:\n",
        "    logging.root.removeHandler(handler)\n",
        "\n",
        "logging.basicConfig(\n",
        "    filename=\"/content/sokoban_log.txt\",  # Change path as needed\n",
        "    filemode='a',                         # Append mode\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "# Before you can make a Sokoban Environment you need to call:\n",
        "# import gym_sokoban\n",
        "# This import statement registers all Sokoban environments\n",
        "# provided by this package\n",
        "\n",
        "\n",
        "'''\n",
        "This info is just for your reference. Easier to know what the number means. The info is copied from sokoban_env.py\n",
        "ACTION_LOOKUP = {\n",
        "    0: 'no operation',\n",
        "    1: 'push up',\n",
        "    2: 'push down',\n",
        "    3: 'push left',\n",
        "    4: 'push right',\n",
        "    5: 'move up',\n",
        "    6: 'move down',\n",
        "    7: 'move left',\n",
        "    8: 'move right',\n",
        "}\n",
        "'''\n",
        "\n",
        "# this class is only responsible for logging\n",
        "class LoggingCallback(BaseCallback):\n",
        "    \"\"\"Logs rewards, actions, and states at each step\"\"\"\n",
        "    def __init__(self, verbose=0):\n",
        "        super().__init__(verbose)\n",
        "        self.rewards_trend = []\n",
        "        self.observations = []\n",
        "        self.verbose = verbose\n",
        "        self.episode_success = 0\n",
        "        self.episode_counter = 0\n",
        "\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        \"\"\"Called at each training step\"\"\"\n",
        "        # for convenience, although it is batch training, we only log and visualize the first item result in the batch\n",
        "        dones = self.locals['dones']\n",
        "        infos = self.locals['infos']\n",
        "\n",
        "        # we only save first episode' (of the whole batch) observation to GIF or PyGame\n",
        "        # observation = self.locals['new_obs'][0]\n",
        "        image_observation = infos[0]['image_observation']\n",
        "        self.observations.append(image_observation)\n",
        "\n",
        "        for i in range(len(dones)):\n",
        "            if dones[i] == True:\n",
        "                self.episode_counter += 1\n",
        "                self.rewards_trend.append(infos[i]['episode']['l'])\n",
        "\n",
        "                if infos[i]['success'] is True:\n",
        "                    self.episode_success += 1\n",
        "                    logging.info(f\"success for env {i}! \")\n",
        "\n",
        "                logging.info(f\"Total steps for env {i}: {infos[i]['episode']['l']}, Total Reward for this episode: {infos[i]['episode']['r']}\")\n",
        "\n",
        "                if self.verbose:\n",
        "                    print(f\"Step: {infos[i]['episode']['r']}, Total Reward for this episode: {infos[i]['episode']['l']}\")\n",
        "                    print(\"returned raw info:\", infos[i])\n",
        "\n",
        "                timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "                if self.episode_counter % 10 == 0:\n",
        "                    create_gif(self.observations.copy(), filename=\"sokoban\" + timestr + \".gif\", success=infos[0][\"success\"], is_maxsteps=infos[0][\"maxsteps_used\"])\n",
        "                    if len(self.rewards_trend) > 1:\n",
        "                        live_plot({'Total Reward': self.rewards_trend})\n",
        "\n",
        "                # if self.episode_counter % 3 == 0:\n",
        "                #     pygame_replay_training_episode(self.observations, success=self.episode_success, maxsteps_used=infos[i]['episode']['l'])\n",
        "                self.observations = []\n",
        "\n",
        "        return True  # Continue training\n",
        "\n",
        "    def get_logs(self):\n",
        "        return {\"rewards\": self.rewards_trend, \"observations\": self.observations}\n",
        "\n",
        "\n",
        "\n",
        "total_reward_trend = []\n",
        "total_steps = 0\n",
        "\n",
        "# this class is only responsible for logging\n",
        "class CurriculumLoggingCallback(BaseCallback):\n",
        "    \"\"\"Logs rewards, actions, and states at each step\"\"\"\n",
        "    def __init__(self, env, threshold=0.8, verbose=0):\n",
        "        super().__init__(verbose)\n",
        "        self.rewards_trend = []\n",
        "        self.observations = []\n",
        "        self.env = env\n",
        "        self.verbose = verbose\n",
        "        self.threshold = threshold\n",
        "        self.episode_success = {}\n",
        "        self.episode_counter = 0\n",
        "\n",
        "    def _on_step(self) -> bool:\n",
        "        \"\"\"Called at each training step\"\"\"\n",
        "        # for convenience, although it is batch training, we only log and visualize the first item result in the batch\n",
        "        dones = self.locals['dones']\n",
        "        infos = self.locals['infos']\n",
        "\n",
        "        ### for real-time game display, we only save first episode' (of the whole batch) observation to GIF or PyGame\n",
        "        # observation = self.locals['new_obs'][0]\n",
        "        image_observation = infos[0]['image_observation']\n",
        "        self.observations.append(image_observation)\n",
        "\n",
        "        # C: Currently, not implement parallelism. dones only contain one item. Write in this way to use parallel env in future\n",
        "        for i in range(len(dones)):\n",
        "            if dones[i] == True:\n",
        "                self.rewards_trend.append(infos[i]['episode']['r'])\n",
        "                self.episode_counter += 1\n",
        "\n",
        "                map_filename = infos[i]['map_filename']\n",
        "\n",
        "                self.episode_success[map_filename] = self.episode_success.get(map_filename, 0) + 1\n",
        "\n",
        "                timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "                if self.episode_counter % 10 == 0:\n",
        "                    create_gif(self.observations, \"sokoban\" + timestr + \".gif\", infos[0]['success'], infos[0]['maxsteps_used'])\n",
        "\n",
        "                # if self.episode_counter % 3 == 0:\n",
        "                #     pygame_replay_training_episode(self.observations, infos[0]['success'], infos[0]['maxsteps_used'])\n",
        "\n",
        "                logging.info(f\"Total steps for env {i}: {infos[i]['episode']['l']}, Total Reward for this episode: {infos[i]['episode']['r']}\")\n",
        "\n",
        "                # assuming each level has 20 maps\n",
        "                if infos[i]['success'] is True:\n",
        "                    logging.info(f\"success for env {i}! \")\n",
        "                    if len(self.episode_success.keys()) >= self.threshold * 20:\n",
        "\n",
        "                        logging.info(f\"level {self.env.current_level} success number: {self.episode_success} has exceeded {self.threshold}, enter into the next level!\")\n",
        "                        print(f\"level {self.env.current_level} success rate has exceeded {self.threshold}, enter into the next level!\")\n",
        "                        self.episode_success = 0\n",
        "                        self.episode_counter = 0\n",
        "                        self.env.advance()\n",
        "                        if getattr(self.env, 'training_done', False):\n",
        "                            print(\"Stopping training: curriculum complete.\")\n",
        "                            return False  # Returning False stops training\n",
        "\n",
        "                if self.verbose:\n",
        "                    print(f\"Total steps for env {i}: {infos[i]['episode']['l']}, Total Reward for this episode: {infos[i]['episode']['r']}\")\n",
        "                    print(\"returned raw info:\", infos[i])\n",
        "\n",
        "                timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "                if self.episode_counter % 10 == 0:\n",
        "                    create_gif(self.observations.copy(), filename=\"sokoban\" + timestr + \".gif\", success=infos[i]['success'], is_maxsteps=infos[i]['episode']['l'])\n",
        "                    if len(self.rewards_trend) > 0:\n",
        "                        live_plot({'Total Reward': self.rewards_trend})\n",
        "\n",
        "                # if self.episode_counter % 3 == 0:\n",
        "                #     pygame_replay_training_episode(self.observations, success=self.episode_success, maxsteps_used=infos[i]['episode']['l'])\n",
        "                self.observations = []\n",
        "\n",
        "\n",
        "        return True  # Continue training\n",
        "\n",
        "    def get_logs(self):\n",
        "        live_plot({'Total Reward': self.rewards_trend})\n",
        "        total_reward_trend.extend(self.rewards_trend)\n",
        "        return {\"current_level\": self.env.current_level, \"episode_success\": self.episode_success}\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0EQpwbc3bdcZ"
      },
      "outputs": [],
      "source": [
        "\"\"\"Common variables & constants definitions.\n",
        "\"\"\"\n",
        "\n",
        "TYPE_LOOKUP_INV = {\n",
        "    0: 'wall',\n",
        "    1: 'empty space',\n",
        "    2: 'box target',\n",
        "    3: 'box on target',\n",
        "    4: 'box not on target',\n",
        "    5: 'player'\n",
        "}\n",
        "\n",
        "# Moves are mapped to coordinate changes as follows\n",
        "# 0: Move up\n",
        "# 1: Move down\n",
        "# 2: Move left\n",
        "# 3: Move right\n",
        "CHANGE_COORDINATES = {\n",
        "    0: (-1, 0),\n",
        "    1: (1, 0),\n",
        "    2: (0, -1),\n",
        "    3: (0, 1)\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AIJ62kozbo_N"
      },
      "outputs": [],
      "source": [
        "def extract_subgoals_from_backward_rollout(backward_agent, env: PullSokobanEnv, num_subgoals=5):\n",
        "    subgoals = []\n",
        "    obs = env.reset()\n",
        "    selected_map = env.selected_map\n",
        "    print(\"selected_map:\", selected_map)\n",
        "\n",
        "    finish_chosen = False\n",
        "    for i in range(num_subgoals):\n",
        "        subgoal_chosen = False\n",
        "        continuous_invalid_actions = []\n",
        "        while not finish_chosen and not subgoal_chosen:\n",
        "            action, _ = backward_agent.predict(obs, deterministic=True)\n",
        "\n",
        "            action = int(action)\n",
        "            obs, _, done, info = env.step(action)\n",
        "\n",
        "\n",
        "            if env.invalid_action:\n",
        "                # print(f\"At subgoal iteration: {i}, action {action} is invalid, skip it.\")\n",
        "                continuous_invalid_actions.append(action)\n",
        "\n",
        "            elif action == 0:\n",
        "                # print(f\"At subgoal iteration: {i}, action 0 is chosen, skip it\")\n",
        "                continuous_invalid_actions.append(action)\n",
        "            else:\n",
        "                print(f\"At subgoal iteration: {i}, action {action} is valid, The action is {PULL_ACTION_LOOKUP[action]}.\")\n",
        "                subgoals.append(env.room_state.copy())\n",
        "                subgoal_chosen = True\n",
        "                continuous_invalid_actions = []\n",
        "\n",
        "            # those room_states do not need to be continuous\n",
        "            if len(continuous_invalid_actions) > 5:\n",
        "                if len(set(continuous_invalid_actions)) == 1:\n",
        "                    print(f\"Continuous same invalid actions: {action}, exit the prediction.\")\n",
        "                    finish_chosen = True\n",
        "                    break\n",
        "                else:\n",
        "                    continuous_invalid_actions.pop(0)\n",
        "\n",
        "            if done:\n",
        "                finish_chosen = True\n",
        "                if info[\"maxsteps_used\"]:\n",
        "                    print(\"maximum steps are used for the pull sokoban env.\")\n",
        "                elif info[\"success\"]:\n",
        "                    print(\"success\")\n",
        "                break\n",
        "\n",
        "\n",
        "    return selected_map, subgoals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dorcyEh1Zs65"
      },
      "outputs": [],
      "source": [
        "def evaluate_agent(agent, env, num_episodes=10):\n",
        "    success = 0\n",
        "    for _ in range(num_episodes):\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            action, _ = agent.predict(obs, deterministic=True)\n",
        "            action = int(action)\n",
        "            obs, _, done, info = env.step(action)\n",
        "        if info.get(\"success\", False):  # Or check agent reached goal\n",
        "            success += 1\n",
        "    return success / num_episodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcIr_iQXRN4p",
        "outputId": "42fb437f-5d86-490e-e230-92ad84d01f09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "please specify selected_map and subgoal_map_array.\n",
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "\n",
            "=== Epoch 0 ===\n",
            "[Training] Backward agent...\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_18.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_2.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_0.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_18.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_19.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_13.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_7.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_16.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_8.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_2.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_2.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_6.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_12.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_11.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_8.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_19.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_8.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_5.txt\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 120       |\n",
            "|    ep_rew_mean     | -1.42e+03 |\n",
            "| time/              |           |\n",
            "|    fps             | 15        |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 130       |\n",
            "|    total_timesteps | 2048      |\n",
            "----------------------------------\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_9.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_0.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_19.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_7.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_6.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_19.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_16.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_4.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_19.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_16.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_14.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_11.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_0.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_9.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_19.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_10.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_16.txt\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 120         |\n",
            "|    ep_rew_mean          | -1.42e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 15          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 259         |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011335061 |\n",
            "|    clip_fraction        | 0.0789      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.19       |\n",
            "|    explained_variance   | -0.000849   |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 9.15e+03    |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00806    |\n",
            "|    value_loss           | 2.13e+04    |\n",
            "-----------------------------------------\n",
            "[Sampling] Subgoals from backward rollouts...\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_4.txt\n",
            "selected_map: ['##########', '##########', '##      ##', '##  .   ##', '##  $   ##', '##  @   ##', '##      ##', '##      ##', '##########', '##########']\n",
            "action in prediction: 5 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 0, action 5 is valid, The action is move up.\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 3 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "action in prediction: 5 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 5 is invalid, skip it.\n",
            "action in prediction: 5 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 5 is invalid, skip it.\n",
            "action in prediction: 5 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 5 is invalid, skip it.\n",
            "action in prediction: 5 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 5 is invalid, skip it.\n",
            "action in prediction: 5 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 5 is invalid, skip it.\n",
            "action in prediction: 5 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 5 is invalid, skip it.\n",
            "Continuous same invalid actions: 5, exit the prediction.\n",
            "selected_map:\n",
            "['##########', '##########', '##      ##', '##  .   ##', '##  $   ##', '##  @   ##', '##      ##', '##      ##', '##########', '##########']\n",
            "subgoals:\n",
            "[array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 3, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])]\n",
            "[Training] Forward agent on subgoals...\n",
            "sg\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 3 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 77.1     |\n",
            "|    ep_rew_mean     | -34      |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 125      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "\n",
            "=== Epoch 1 ===\n",
            "[Training] Backward agent...\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_2.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_4.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_5.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_2.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_4.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_6.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_5.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_2.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_3.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_6.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_18.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_6.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_9.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_9.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_14.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_12.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_0.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_2.txt\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 120       |\n",
            "|    ep_rew_mean     | -1.44e+03 |\n",
            "| time/              |           |\n",
            "|    fps             | 16        |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 126       |\n",
            "|    total_timesteps | 2048      |\n",
            "----------------------------------\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_9.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_2.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_4.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_0.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_10.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_0.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_8.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_11.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_14.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_17.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_19.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_8.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_14.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_14.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_7.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_2.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_9.txt\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 120         |\n",
            "|    ep_rew_mean          | -1.43e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 16          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 255         |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011650119 |\n",
            "|    clip_fraction        | 0.075       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.18       |\n",
            "|    explained_variance   | -4.29e-06   |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 1e+04       |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.00882    |\n",
            "|    value_loss           | 2.23e+04    |\n",
            "-----------------------------------------\n",
            "[Sampling] Subgoals from backward rollouts...\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_11.txt\n",
            "selected_map: ['##########', '##########', '##      ##', '##      ##', '## $   .##', '##      ##', '## @    ##', '##      ##', '##########', '##########']\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 0, action 6 is valid, The action is move down.\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 3 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 5 1 1 1 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 6 is invalid, skip it.\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 6 is invalid, skip it.\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 6 is invalid, skip it.\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 6 is invalid, skip it.\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 6 is invalid, skip it.\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 6 is invalid, skip it.\n",
            "Continuous same invalid actions: 6, exit the prediction.\n",
            "selected_map:\n",
            "['##########', '##########', '##      ##', '##      ##', '## $   .##', '##      ##', '## @    ##', '##      ##', '##########', '##########']\n",
            "subgoals:\n",
            "[array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 3, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 5, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])]\n",
            "[Training] Forward agent on subgoals...\n",
            "sg\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 3 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 5 1 1 1 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 93       |\n",
            "|    ep_rew_mean     | -103     |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 127      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "\n",
            "=== Epoch 2 ===\n",
            "[Training] Backward agent...\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_12.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_7.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_15.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_15.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_19.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_16.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_15.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_14.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_8.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_15.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_14.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_10.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_18.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_3.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_15.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_19.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_10.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_0.txt\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 120      |\n",
            "|    ep_rew_mean     | -1.4e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 126      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_11.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_5.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_10.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_9.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_16.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_19.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_6.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_16.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_9.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_4.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_2.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_8.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_6.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_6.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_5.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_11.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_13.txt\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 120         |\n",
            "|    ep_rew_mean          | -1.41e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 15          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 256         |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007634191 |\n",
            "|    clip_fraction        | 0.0702      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.14       |\n",
            "|    explained_variance   | -2.26e-06   |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 9.96e+03    |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.00602    |\n",
            "|    value_loss           | 1.94e+04    |\n",
            "-----------------------------------------\n",
            "[Sampling] Subgoals from backward rollouts...\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_2.txt\n",
            "selected_map: ['##########', '##########', '##      ##', '##      ##', '## @$.  ##', '##      ##', '##      ##', '##      ##', '##########', '##########']\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 0, action 6 is valid, The action is move down.\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 2 1 1 0 0]\n",
            " [0 0 1 5 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 6 is valid, The action is move down.\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 2 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 5 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 2, action 6 is valid, The action is move down.\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 2 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 5 1 1 1 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 3, action 6 is invalid, skip it.\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 3, action 6 is invalid, skip it.\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 3, action 6 is invalid, skip it.\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 3, action 6 is invalid, skip it.\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 3, action 6 is invalid, skip it.\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 3, action 6 is invalid, skip it.\n",
            "Continuous same invalid actions: 6, exit the prediction.\n",
            "selected_map:\n",
            "['##########', '##########', '##      ##', '##      ##', '## @$.  ##', '##      ##', '##      ##', '##      ##', '##########', '##########']\n",
            "subgoals:\n",
            "[array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 2, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 5, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 2, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 5, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 2, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 5, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])]\n",
            "[Training] Forward agent on subgoals...\n",
            "sg\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 2 1 1 0 0]\n",
            " [0 0 1 5 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 78.6     |\n",
            "|    ep_rew_mean     | -41.2    |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 126      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "sg\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 2 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 5 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 66.8     |\n",
            "|    ep_rew_mean     | -28.4    |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 127      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "sg\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 2 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 5 1 1 1 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 56.8     |\n",
            "|    ep_rew_mean     | -22.6    |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 127      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "\n",
            "=== Epoch 3 ===\n",
            "[Training] Backward agent...\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_7.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_10.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_9.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_14.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_12.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_7.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_16.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_9.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_11.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_16.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_2.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_19.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_11.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_0.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_18.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_8.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_6.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_5.txt\n",
            "----------------------------------\n",
            "| rollout/           |           |\n",
            "|    ep_len_mean     | 120       |\n",
            "|    ep_rew_mean     | -1.41e+03 |\n",
            "| time/              |           |\n",
            "|    fps             | 16        |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 126       |\n",
            "|    total_timesteps | 2048      |\n",
            "----------------------------------\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_10.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_17.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_5.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_19.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_6.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_19.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_0.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_5.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_13.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_3.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_9.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_19.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_10.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_2.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_10.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_14.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_8.txt\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 120         |\n",
            "|    ep_rew_mean          | -1.41e+03   |\n",
            "| time/                   |             |\n",
            "|    fps                  | 15          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 256         |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015397476 |\n",
            "|    clip_fraction        | 0.121       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.15       |\n",
            "|    explained_variance   | -5.96e-07   |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 7.33e+03    |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00997    |\n",
            "|    value_loss           | 1.8e+04     |\n",
            "-----------------------------------------\n",
            "[Sampling] Subgoals from backward rollouts...\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_11.txt\n",
            "selected_map: ['##########', '##########', '##      ##', '##      ##', '## $   .##', '##      ##', '## @    ##', '##      ##', '##########', '##########']\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 0, action 6 is valid, The action is move down.\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 3 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 5 1 1 1 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 6 is invalid, skip it.\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 6 is invalid, skip it.\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 6 is invalid, skip it.\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 6 is invalid, skip it.\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 6 is invalid, skip it.\n",
            "action in prediction: 6 <class 'numpy.ndarray'>\n",
            "At subgoal iteration: 1, action 6 is invalid, skip it.\n",
            "Continuous same invalid actions: 6, exit the prediction.\n",
            "selected_map:\n",
            "['##########', '##########', '##      ##', '##      ##', '## $   .##', '##      ##', '## @    ##', '##      ##', '##########', '##########']\n",
            "subgoals:\n",
            "[array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 3, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 1, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 1, 5, 1, 1, 1, 1, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])]\n",
            "[Training] Forward agent on subgoals...\n",
            "sg\n",
            "[[0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 3 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 1 5 1 1 1 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0]]\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 81.8     |\n",
            "|    ep_rew_mean     | -85.7    |\n",
            "| time/              |          |\n",
            "|    fps             | 16       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 126      |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "import gym\n",
        "\n",
        "# === 1. Create base Sokoban environment ===\n",
        "steps = 10000\n",
        "total_steps = steps\n",
        "\n",
        "policy_kwargs = dict(\n",
        "    net_arch=[dict(pi=[256, 256], vf=[256, 256])]\n",
        ")\n",
        "\n",
        "forward_env = CustomizeSokobanEnv()\n",
        "forward_agent = PPO(\"MlpPolicy\", forward_env,\n",
        "                n_steps=2048,             # Should be a multiple of vec_envs (if used)\n",
        "                batch_size=32,            # Smaller batch size may help with stability\n",
        "                gae_lambda=0.95,\n",
        "                gamma=0.99,\n",
        "                n_epochs=10,\n",
        "                learning_rate=1e-4,\n",
        "                clip_range=0.2,\n",
        "                policy_kwargs=policy_kwargs,\n",
        "                verbose=1)\n",
        "\n",
        "\n",
        "# === 2. Create agents ===\n",
        "backward_env = PullSokobanEnv()\n",
        "backward_agent = PPO(\"MlpPolicy\", backward_env,\n",
        "                n_steps=2048,             # Should be a multiple of vec_envs (if used)\n",
        "                batch_size=32,            # Smaller batch size may help with stability\n",
        "                gae_lambda=0.95,\n",
        "                gamma=0.99,\n",
        "                n_epochs=10,\n",
        "                learning_rate=1e-4,\n",
        "                clip_range=0.2,\n",
        "                policy_kwargs=policy_kwargs,\n",
        "                verbose=1)\n",
        "\n",
        "# === 3. Hybrid training loop ===\n",
        "num_epochs = 4\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\n=== Epoch {epoch} ===\")\n",
        "\n",
        "    # (A) Train backward agent (learn subgoal generation)\n",
        "    print(\"[Training] Backward agent...\")\n",
        "    backward_agent.learn(total_timesteps=2500)\n",
        "\n",
        "    # (B) Extract subgoals from backward rollouts\n",
        "    print(\"[Sampling] Subgoals from backward rollouts...\")\n",
        "    # when extract sub goals from bafkward rollout,\n",
        "    selected_map, subgoals = extract_subgoals_from_backward_rollout(backward_agent, backward_env, num_subgoals=5)\n",
        "\n",
        "    # (C) Train forward agent to reach each subgoal\n",
        "    print(\"[Training] Forward agent on subgoals...\")\n",
        "    for sg in subgoals:\n",
        "        forward_env = CustomizeSokobanEnv(selected_map, subgoal_map_array=sg)\n",
        "        observation = forward_env.reset()\n",
        "        ACTION_LOOKUP = forward_env.get_action_lookup()\n",
        "\n",
        "        # Attach the callback when training the model\n",
        "        callback = CurriculumLoggingCallback(forward_env, verbose=0)\n",
        "\n",
        "        forward_agent.set_env(forward_env)\n",
        "        forward_agent.learn(total_timesteps=500)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hksPwtKeaY90",
        "outputId": "4b13f8e0-d234-4ae4-d82e-c8ccdef45821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Final Evaluation on Forward Agent:\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_18.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_16.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_17.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_9.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_18.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_0.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_5.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_13.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_12.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_7.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_18.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_6.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_13.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_2.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_8.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_0.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_0.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_16.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_6.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_5.txt\n",
            "/content/drive/MyDrive/gym-sokoban/human_demos/1_3.txt\n",
            "Success rate: 5.00%\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n✅ Final Evaluation on Forward Agent:\")\n",
        "test_env = TestSokobanEnv(1, 4,  num_boxes = 3, verbose=False, max_steps = 100)\n",
        "success_rate = evaluate_agent(forward_agent, test_env, num_episodes=20)\n",
        "print(f\"Success rate: {success_rate * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
